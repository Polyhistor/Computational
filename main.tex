\documentclass[a4paper,12pt]{article}
\usepackage[utf8]{inputenc}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{natbib}
\usepackage{url}
\usepackage{tabularx}
\usepackage{booktabs}

\title{Computational Mathematics for AI: Numerical Methods and Distributed Computing for Deep Learning on Big Data}
\author{Pouya Ataei}
\date{\today}

\begin{document}

\maketitle

\section{Introduction}
This document outlines the protocol for a systematic literature review (SLR) on computational mathematics for AI, focusing on numerical methods and distributed computing techniques for deep learning on big data. The review will follow the PRISMA guidelines \citep{moher2009preferred} and Kitchenham's methodology for SLRs in software engineering \citep{kitchenham2007guidelines}.

\section{Background}
\subsection{Rationale}
As deep learning models grow in complexity and data volumes continue to increase, there is a critical need to understand and optimize the computational methods underpinning these systems. This review aims to synthesize current knowledge on numerical methods and distributed computing techniques specifically applied to deep learning in big data contexts.

\subsection{Objectives}
The primary objectives of this SLR are:
\begin{enumerate}
    \item To identify and categorize state-of-the-art numerical methods used in deep learning for big data.
    \item To evaluate the effectiveness of various distributed computing techniques for scaling deep learning to big data problems.
    \item To compare these methods and techniques in terms of computational efficiency, scalability, and accuracy.
    \item To identify emerging trends and future directions in this field.
\end{enumerate}

\section{Research Methodology}

This study employs a comprehensive approach combining two systematic literature reviews (SLRs) with subsequent meta-analysis and network analysis. The methodology is structured into seven distinct phases:

\subsection{Phase 1: Planning and Protocol Development}

\subsubsection{Research Questions}
For SLR 1 (Numerical Methods):
\begin{enumerate}
    \item[RQ1.1] What are the state-of-the-art numerical methods used in deep learning for big data?
    \item[RQ1.2] How do these methods perform in terms of computational efficiency and accuracy?
\end{enumerate}

For SLR 2 (Distributed Computing Techniques):
\begin{enumerate}
    \item[RQ2.1] What distributed computing techniques are used for scaling deep learning to big data problems?
    \item[RQ2.2] How effective are these techniques in terms of scalability and performance?
\end{enumerate}

\subsubsection{Literature Review Classification Framework}
We will use Cooper's taxonomy \citep{cooper1988} to classify the literature in both SLRs:

\begin{table}[h]
\caption{Adaptation of Cooper's Literature Review Taxonomy}
\begin{tabularx}{\textwidth}{lX}
\toprule
Characteristic & Categories \\
\midrule
(a) Focus     & Research outcomes, Research methods, Theories, Practices or applications \\
(b) Goal      & Integration, Criticism, Identification of central issues \\
(c) Perspective & Neutral representation, Espousal of position \\
(d) Coverage  & Exhaustive, Exhaustive with selective citation, Representative, Central or pivotal \\
(e) Organization & Historical, Conceptual, Methodological \\
(f) Audience  & Specialized scholars, General scholars, Practitioners or policymakers, General public \\
\bottomrule
\end{tabularx}
\end{table}

This classification will be applied to each included study during the data extraction phase. It will help us to:

\begin{itemize}
    \item Systematically categorize the nature and scope of each study
    \item Identify patterns and trends in the literature
    \item Ensure a balanced representation of different types of research in our review
    \item Tailor our findings to different audience needs
    \item Guide our analysis and synthesis of the literature
\end{itemize}

The classification results will be used in Phase 6 (Study Classification and Bias Assessment) to provide additional context for interpreting our findings and identifying gaps in the current research landscape.

\subsubsection{Search Strategy Development}
PICO-based search strings for each SLR:

SLR 1:
\begin{verbatim}
("deep learning"
AND 
("numerical method*" 
OR "computational mathematics" 
OR "optimization algorithm*")
AND 
("big data"))
\end{verbatim}


\emph{IEEE Explore Search String:}

(("deep learning" AND ("numerical method*" OR "computational mathematics" OR "optimization algorithm*") AND ("big data")))

\emph{Scopus Search String:}

( TITLE-ABS ( "deep learning" ) AND ( TITLE-ABS ( "numerical method*" OR "computational mathematics" OR "optimization algorithm*" ) ) AND TITLE-ABS ( "big data" ) )


SLR 2:
\begin{verbatim}
(("deep learning" OR "neural network*") AND 
("distributed computing" OR "parallel processing" OR 
"GPU acceleration" OR "federated learning") AND 
("big data" OR "large-scale") AND 
(scalability OR performance))
\end{verbatim}

\subsubsection{Information Sources}
IEEE Xplore, ACM Digital Library, SpringerLink, Scopus, Web of Science, JSTOR, AIS 

\subsubsection{Eligibility Criteria}
Inclusion:
\begin{itemize}
    \item Studies from 2014-2024
    \item Peer-reviewed journal articles and conference papers
    \item English language publications
    \item Directly addressing the respective SLR focus
\end{itemize}

Exclusion:
\begin{itemize}
    \item Studies not focusing on big data scenarios
    \item Publications without clear methodological details
    \item Review papers
\end{itemize}

\subsection{Phase 2: Literature Search and Study Selection}

\begin{enumerate}
    \item Execute search strategy on selected databases
    \item Import results to reference management software
    \item Remove duplicates
    \item Initial screening of titles and abstracts
    \item Full-text assessment of potentially eligible studies
    \item Document selection process using PRISMA flow diagram
\end{enumerate}

\subsection{Phase 3: Data Extraction and Quality Assessment}

\subsubsection{Data Extraction}
Using a standardized, pre-piloted form to extract:
\begin{itemize}
    \item Bibliographic information
    \item Methods/techniques used
    \item Problem domain and dataset characteristics
    \item Performance metrics
    \item Hardware and software environment
    \item Key findings and limitations
\end{itemize}

\subsubsection{Quality Assessment}
\subsection{Quality Assessment}
The quality of individual studies will be assessed using a criteria made up of 7 elements, inspired by the CASP checklist for assessing qualitative research and Kitchenham's guidelines on empirical research in software engineering . This assessment will be applied to studies in both SLRs.

\subsubsection{Quality Assessment Criteria}
The criteria test literature on 4 major areas:

\paragraph{1. Minimum quality threshold:}
\begin{itemize}
    \item Does the study report empirical research or is it merely a 'lesson learnt' report based on expert opinion?
    \item Are the objectives and aims of the study clearly communicated, including the reasoning for why the study was undertaken?
    \item Does the study provide adequate information regarding the context in which the research was carried out?
\end{itemize}

\paragraph{2. Rigour:}
\begin{itemize}
    \item Is the research design appropriate to address the objectives of the research?
    \item Is there a data collection method used and is it appropriate?
\end{itemize}

\paragraph{3. Credibility:}
\begin{itemize}
    \item Does the study report findings in a clear and unbiased manner?
\end{itemize}

\paragraph{4. Relevance:}
\begin{itemize}
    \item Does the study provide value for practice or research?
\end{itemize}

\subsubsection{Assessment Process}
\begin{enumerate}
    \item The assessment will be conducted in two phases:
    \begin{itemize}
        \item Phase 1: Assess only the minimum quality threshold criteria.
        \item Phase 2: If a study passes Phase 1, assess it for rigour, credibility, and relevance.
    \end{itemize}
    \item Two reviewers will independently assess each study.
    \item Each criterion will be scored as either 'yes' or 'no'.
    \item A study passes the quality assessment if it receives positive responses for at least 75\% of the criteria.
    \item Inter-rater reliability will be assessed using Krippendorff's alpha, aiming for q > 0.8.
    \item Disagreements will be resolved through discussion. If consensus cannot be reached, a third reviewer will be consulted.
\end{enumerate}

\subsubsection{Quality Threshold}
To be included in the final analysis, a study must:
\begin{itemize}
    \item Pass all criteria in the minimum quality threshold category (Phase 1)
    \item Receive positive responses for at least 75\% of all criteria (Phase 1 and 2 combined)
    \item Achieve at least 75\% inter-rater reliability
\end{itemize}

This quality assessment framework will ensure that only studies meeting a minimum standard of methodological rigour and relevance are included in our analysis, thereby enhancing the reliability and validity of our findings.

Quality threshold: 75\% positive responses, 75\% inter-rater reliability (Krippendorff's q > 0.8)

\subsection{Phase 4: Data Synthesis for Individual SLRs}

For each SLR:
\begin{itemize}
    \item Narrative synthesis of findings
    \item Categorization of methods/techniques
    \item Analysis of performance metrics
\end{itemize}

\subsection{Phase 5: Combined Analysis}

\subsubsection{Meta-Analysis}
\begin{itemize}
    \item Random-effects model for common outcome measures
    \item Forest plots for combined effect sizes
    \item Subgroup analyses for different categories
\end{itemize}

\subsubsection{Network Analysis}
\begin{itemize}
    \item Comprehensive network graph
    \item Community detection
    \item Centrality measure analysis
\end{itemize}

\subsection{Phase 6: Study Classification and Bias Assessment}

\subsubsection{Study Classification}
Classify all studies according to Cooper's taxonomy:
\begin{itemize}
    \item Focus, Goal, Perspective, Coverage, Organization, Audience
\end{itemize}

\subsubsection{Assessment of Meta-Bias}
\begin{itemize}
    \item Funnel plot examination
    \item Egger's test for small-study effects
\end{itemize}

\subsection{Phase 7: Synthesis and Reporting}

\begin{itemize}
    \item Compare and contrast findings from both SLRs
    \item Identify synergies between numerical methods and distributed computing techniques
    \item Discuss trade-offs between efficiency, scalability, and accuracy
    \item Highlight emerging trends and future research directions
    \item Assess confidence in cumulative evidence using GRADE approach
    \item Prepare final report following PRISMA guidelines
\end{itemize}

This phased approach ensures a systematic and comprehensive review of computational mathematics for AI in big data contexts, combining insights from numerical methods and distributed computing techniques.

\section{Discussion}
This systematic review will provide a comprehensive overview of the current state of numerical methods and distributed computing techniques for deep learning on big data. The findings will be interpreted considering the strength of evidence, applicability, and generalizability. Limitations of the review and the included studies will be discussed, and implications for future research will be outlined.

\bibliographystyle{apalike}
\bibliography{references}

\end{document}
